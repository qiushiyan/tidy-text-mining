
# (PART) Text Mining with R {-}

# Tidy text format  

```{r, echo = FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

A "tidy" text format is defined as a per-token-per row data frame. This one-token-per-row structure is in contrast to the ways text is often stored in current analyses, perhaps as strings or in a document-term matrix (Chapter \@ref(converting-to-and-from-non-tidy-formats)). For tidy text mining, the token that is stored in each row is most often a single word, but can also be an n-gram, sentence, or paragraph. In the tidytext package, we provide functionality to tokenize by commonly used units of text like these and convert to a one-term-per-row format. 

## The `unnest_tokens()` function

```{r}
library(janeaustenr)
```

```{r}
austen_books()
```


```{r}
original_books <- austen_books() %>%
  group_by(book) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
                                                 ignore_case = TRUE)))) %>%
  ungroup()

original_books
```


```{r}
original_books %>%
  unnest_tokens(word, text)
```

```{r}
stop_words 

tidy_books <- original_books %>%
  unnest_tokens(word, text) %>% 
  anti_join(stop_words)

tidy_books
```


## The `gutenbergr` package   

```{r}
library(gutenbergr)
```

The gutenbergr package provides access to the public domain works from the Project Gutenberg collection. The package includes tools both for downloading books (stripping out the unhelpful header/footer information), and a complete dataset of Project Gutenberg metadata that can be used to find works of interest. In this book, we will mostly use the function `gutenberg_download()` that downloads one or more works from Project Gutenberg by ID.  

The dataset gutenberg_metadata contains information about each work, pairing Gutenberg ID with title, author, language, etc:  

```{r}
gutenberg_metadata
```




For example, you could find the Gutenberg ID of Wuthering Heights by doing:  

```{r}
gutenberg_metadata %>%
  filter(title == "Wuthering Heights")

gutenberg_download(768)
```


In many analyses, you may want to filter just for English works, avoid duplicates, and include only books that have text that can be downloaded. The `gutenberg_works()` function does this pre-filtering. It also allows you to perform filtering as an argument:

```{r}
gutenberg_works(author == "Austen, Jane")
```


## Compare word frequency  

As a common task in text analysis, compariosn of word frequencies is often employed as a tool to extract linguistic characteristics. A rule of thumb is to compare word **proportions** instead of raw counts.  

In this example, we compare novels of Jane Austen, H.G. Wells, and the Bronte Sisters. 

```{r}
austen <- austen_books() %>% 
  select(-book) %>% 
  mutate(author = "Jane Austen")
bronte <- gutenberg_download(c(1260, 768, 969, 9182, 767)) %>%
  select(-gutenberg_id) %>% 
  mutate(author = "Brontë Sisters")
hgwells <- gutenberg_download(c(35, 36, 5230, 159)) %>% 
  select(-gutenberg_id) %>% 
  mutate(author = "H.G. Wells")

tidy_book <- function(author) {
  author %>% 
    unnest_tokens(word, text) %>% 
    anti_join(stop_words)
}



books <- bind_rows(tidy_book(austen),
          tidy_book(bronte),
          tidy_book(hgwells)) %>% 
  mutate(word = str_extract(word, "[:alpha:]+")) %>% 
  count(author, word, sort = TRUE)
```


```{r}
books
```

Now, our goal is to use Jane Austen as a reference to which the other two authors are compared to in terms of word frequency. The data manipulation requires a bit trick, after computing proportions of word usage, we first `pivot_wider` three authors altogether, an then `pivot_longer` the other two authors back.  

```{r}
comparison_df <- books %>%
  add_count(author, wt = n, name = "total_word") %>% 
  mutate(proportion = n / total_word) %>% 
  select(-total_word, -n) %>% 
  pivot_wider(names_from = author, values_from = proportion, 
              values_fill = list(proportion = 0)) %>%
  pivot_longer(3:4, names_to = "other", values_to = "proportion")

comparison_df
```


```{r, fig.height = 8, fig.width = 10}
library(scales)

comparison_df %>% 
  filter(proportion > 1 / 1e5) %>% 
  ggplot(aes(proportion, `Jane Austen`)) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(aes(color = abs(`Jane Austen` - proportion)),
              alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) + 
  scale_x_log10(labels = label_percent()) +
  scale_y_log10(labels = label_percent()) + 
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") + 
  facet_wrap(~ other) + 
  guides(color = FALSE)
```

Words that are close to the line in these plots have similar frequencies in both sets of texts, for example, in both Austen and Brontë texts (“miss”, “time”, “day” at the upper frequency end) or in both Austen and Wells texts (“time”, “day”, “brother” at the high frequency end). Words that are far from the line are words that are found more in one set of texts than another. For example, in the Austen-Brontë panel, words like “elizabeth”, “emma”, and “fanny” (all proper nouns) are found in Austen’s texts but not much in the Brontë texts, while words like “arthur” and “dog” are found in the Brontë texts but not the Austen texts. In comparing H.G. Wells with Jane Austen, Wells uses words like “beast”, “guns”, “feet”, and “black” that Austen does not, while Austen uses words like “family”, “friend”, “letter”, and “dear” that Wells does not.

Notice that  the words in the Austen-Brontë panel are closer to the zero-slope line than in the Austen-Wells panel. Also notice that the words extend to lower frequencies in the Austen-Brontë panel; there is empty space in the Austen-Wells panel at low frequency. These characteristics indicate that Austen and the Brontë sisters use more similar words than Austen and H.G. Wells. Also, we see that not all the words are found in all three sets of texts and there are fewer data points in the panel for Austen and H.G. Wells.

Furhter, we can conduct a simple correlation test

```{r}
cor.test(data = filter(comparison_df, other == "Brontë Sisters"),
         ~ proportion + `Jane Austen`)

cor.test(data = filter(comparison_df, other == "H.G. Wells"),
         ~ proportion + `Jane Austen`)
```


## Other tokenization methods  

`unnest_tokens` supports other ways to split a column into tokens. 

```{r}
text <- c("This is, my bookdown book.",
          "Chapter 1: Preface\n", 
          "Thanks for \n reading this book\n",
          "Chapter 2: Introduction\n",
          "Chapter 3: Methods\n",
          "I demonstrate all of the methods here,",
          "well, not all actually.\n\n",
          "Chapter 4: Discussion\n",
          "blablabla,",
          "blablabla,",
          "blablabla.")
df <- tibble(text = text)
cat(df$text)
```




```{r}
# lines
df %>% unnest_tokens(line, text, token = "lines")
# sentences, split by period
df %>% unnest_tokens(sentences, text, token = "sentences")
# paragraphs
df %>% unnest_tokens(paragraphs, text, token = "paragraphs")
```


```{r}
# split into characters or multiple characters 
df %>% unnest_tokens(character, text, token = "characters")
df %>% unnest_tokens(characters, text, token = "character_shingles", n = 4)
```

```{r}
# split by regex
df %>% 
  unnest_tokens(chapter, text, token = "regex", pattern = "Chapter \\d:")
```
